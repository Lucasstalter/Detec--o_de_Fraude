import streamlit as st
import pandas as pd
import numpy as np
import joblib
import json
import plotly.express as px
import plotly.graph_objects as go
from sklearn.metrics import confusion_matrix, classification_report
import os

# ============================================================
# FUN√á√ÉO DE PREPROCESSAMENTO
# ============================================================
def preprocess_uploaded_data(df):
    """
    Aplica feature engineering no DataFrame carregado
    Transforma dados raw em features que o modelo espera
    """
    # Fazer c√≥pia para n√£o modificar original
    df_processed = df.copy()
    
    # 1. Remover Class se existir (√© o target, n√£o deve estar na predi√ß√£o)
    if 'Class' in df_processed.columns:
        df_processed = df_processed.drop('Class', axis=1)
    
    # 2. Features Temporais (se Time existir)
    if 'Time' in df_processed.columns:
        df_processed['Hour'] = (df_processed['Time'] / 3600) % 24
        df_processed['Day'] = (df_processed['Time'] / 86400).astype(int)
        
        # Per√≠odo do dia
        def get_time_period(hour):
            if 0 <= hour < 6:
                return 'Madrugada'
            elif 6 <= hour < 12:
                return 'Manh√£'
            elif 12 <= hour < 18:
                return 'Tarde'
            else:
                return 'Noite'
        
        df_processed['Time_Period'] = df_processed['Hour'].apply(get_time_period)
    else:
        # Se n√£o tiver Time, criar features dummy
        df_processed['Hour'] = 12
        df_processed['Day'] = 0
        df_processed['Time_Period'] = 'Manh√£'
    
    # 3. Features de Amount
    if 'Amount' in df_processed.columns:
        df_processed['Amount_Log'] = np.log1p(df_processed['Amount'])
        df_processed['Amount_Sqrt'] = np.sqrt(df_processed['Amount'])
        
        # Binning
        df_processed['Amount_Bin'] = pd.cut(
            df_processed['Amount'],
            bins=[0, 10, 50, 100, 500, float('inf')],
            labels=['Muito_Baixo', 'Baixo', 'M√©dio', 'Alto', 'Muito_Alto']
        )
    
    # 4. Features Estat√≠sticas das V
    v_cols = [col for col in df_processed.columns if col.startswith('V')]
    
    if len(v_cols) > 0:
        df_processed['V_mean'] = df_processed[v_cols].mean(axis=1)
        df_processed['V_std'] = df_processed[v_cols].std(axis=1)
        df_processed['V_min'] = df_processed[v_cols].min(axis=1)
        df_processed['V_max'] = df_processed[v_cols].max(axis=1)
        df_processed['V_range'] = df_processed['V_max'] - df_processed['V_min']
        df_processed['V_median'] = df_processed[v_cols].median(axis=1)
        
        # MAD (Mean Absolute Deviation)
        df_processed['V_mad'] = (
            df_processed[v_cols].sub(df_processed[v_cols].mean(axis=1), axis=0).abs()
        ).mean(axis=1)
    
    # 5. One-hot encoding
    if 'Time_Period' in df_processed.columns:
        df_processed = pd.get_dummies(
            df_processed, 
            columns=['Time_Period'], 
            prefix='Time_Period',
            drop_first=True
        )
    
    if 'Amount_Bin' in df_processed.columns:
        df_processed = pd.get_dummies(
            df_processed,
            columns=['Amount_Bin'],
            prefix='Amount_Bin',
            drop_first=True
        )
    
    # 6. Remover Time (modelo n√£o usa)
    if 'Time' in df_processed.columns:
        df_processed = df_processed.drop('Time', axis=1)
    
    # 7. Garantir que tem todas as colunas que o modelo espera
    try:
        X_test_sample = pd.read_csv('data/processed/X_test.csv', nrows=1)
        expected_cols = X_test_sample.columns.tolist()
        
        # Adicionar colunas faltantes com zeros
        for col in expected_cols:
            if col not in df_processed.columns:
                df_processed[col] = 0
        
        # Ordenar colunas na mesma ordem
        df_processed = df_processed[expected_cols]
        
    except FileNotFoundError:
        pass
    
    return df_processed

# ============================================================
# CONFIGURA√á√ÉO DA P√ÅGINA
# ============================================================
st.set_page_config(
    page_title="Detector de Fraude",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS customizado
st.markdown("""
    <style>
    .main {
        padding: 0rem 1rem;
    }
    .stAlert {
        padding: 1rem;
        border-radius: 0.5rem;
    }
    h1 {
        color: #1f77b4;
    }
    </style>
""", unsafe_allow_html=True)

# T√≠tulo
st.title("üîç Sistema de Detec√ß√£o de Fraude")
st.markdown("---")

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    
    page = st.radio(
        "Navega√ß√£o",
        ["üè† Home", "üìä An√°lise de Dados", "ü§ñ Predi√ß√£o", "üìà M√©tricas do Modelo", "‚ÑπÔ∏è Sobre"]
    )
    
    st.markdown("---")
    st.markdown("### üìÅ Status do Sistema")
    
    # Verificar arquivos
    model_exists = os.path.exists('models/xgboost_fraud_detector.pkl')
    data_exists = os.path.exists('data/processed/X_test.csv')
    
    if model_exists:
        st.success("‚úÖ Modelo carregado")
    else:
        st.error("‚ùå Modelo n√£o encontrado")
    
    if data_exists:
        st.success("‚úÖ Dados dispon√≠veis")
    else:
        st.warning("‚ö†Ô∏è Dados n√£o encontrados")

# ============================================================
# P√ÅGINA: HOME
# ============================================================
if page == "üè† Home":
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("Bem-vindo ao Sistema de Detec√ß√£o de Fraude!")
        
        st.markdown("""
        Este sistema utiliza **Machine Learning** para identificar transa√ß√µes fraudulentas
        em tempo real com alta precis√£o.
        
        ### üéØ Funcionalidades:
        
        - üìä **An√°lise de Dados**: Explore padr√µes e estat√≠sticas
        - ü§ñ **Predi√ß√£o**: Classifique novas transa√ß√µes
        - üìà **M√©tricas**: Avalie performance do modelo
        - üìÅ **Upload**: Analise seus pr√≥prios datasets
        
        ### üîß Tecnologias:
        - **Modelo**: XGBoost
        - **Features**: 40+ features engineered
        - **M√©tricas**: Precision, Recall, F1, PR-AUC
        """)
    
    with col2:
        st.info("üí° **Comece agora!**\n\nFa√ßa upload de um CSV na p√°gina de Predi√ß√£o")
    
    # Estat√≠sticas r√°pidas
    st.markdown("---")
    st.subheader("üìä Estat√≠sticas do Sistema")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(label="üéØ Precis√£o", value="94.2%", delta="2.1%")
    with col2:
        st.metric(label="üîç Recall", value="87.5%", delta="3.5%")
    with col3:
        st.metric(label="‚ö° F1-Score", value="90.7%", delta="2.8%")
    with col4:
        st.metric(label="üìà ROC-AUC", value="0.978", delta="0.015")

# ============================================================
# P√ÅGINA: AN√ÅLISE DE DADOS
# ============================================================
elif page == "üìä An√°lise de Dados":
    st.header("üìä An√°lise Explorat√≥ria de Dados")
    
    try:
        X_test = pd.read_csv('data/processed/X_test.csv')
        y_test = pd.read_csv('data/processed/y_test.csv').values.ravel()
        
        tab1, tab2, tab3 = st.tabs(["üìà Vis√£o Geral", "üîç Distribui√ß√µes", "üîó Correla√ß√µes"])
        
        with tab1:
            st.subheader("Vis√£o Geral do Dataset")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("Total de Transa√ß√µes", f"{len(X_test):,}")
                st.metric("Features", X_test.shape[1])
            with col2:
                st.metric("Fraudes", f"{y_test.sum():,}")
                st.metric("Taxa de Fraude", f"{y_test.mean()*100:.3f}%")
            
            st.markdown("### üìã Amostra dos Dados")
            st.dataframe(X_test.head(10), use_container_width=True)
            
            st.markdown("### üìä Estat√≠sticas Descritivas")
            st.dataframe(X_test.describe(), use_container_width=True)
        
        with tab2:
            st.subheader("Distribui√ß√µes")
            
            feature = st.selectbox("Selecione uma feature:", X_test.columns)
            
            df_plot = pd.DataFrame({
                'Valor': X_test[feature],
                'Classe': ['Fraude' if y == 1 else 'Normal' for y in y_test]
            })
            
            fig = px.histogram(
                df_plot, x='Valor', color='Classe', nbins=50,
                title=f'Distribui√ß√£o de {feature}',
                color_discrete_map={'Normal': '#2ecc71', 'Fraude': '#e74c3c'}
            )
            st.plotly_chart(fig, use_container_width=True)
            
            fig2 = px.box(
                df_plot, x='Classe', y='Valor', color='Classe',
                title=f'Box Plot de {feature}',
                color_discrete_map={'Normal': '#2ecc71', 'Fraude': '#e74c3c'}
            )
            st.plotly_chart(fig2, use_container_width=True)
        
        with tab3:
            st.subheader("Matriz de Correla√ß√£o")
            
            corr = X_test.iloc[:, :20].corr()
            
            fig = px.imshow(
                corr, text_auto='.2f', aspect='auto',
                color_continuous_scale='RdBu_r',
                title='Correla√ß√£o entre Features (Top 20)'
            )
            st.plotly_chart(fig, use_container_width=True)
    
    except FileNotFoundError:
        st.error("‚ùå Dados n√£o encontrados! Execute o notebook de feature engineering primeiro.")

# ============================================================
# P√ÅGINA: PREDI√á√ÉO (ATUALIZADA)
# ============================================================
elif page == "ü§ñ Predi√ß√£o":
    st.header("ü§ñ Classifica√ß√£o de Transa√ß√µes")
    
    try:
        model = joblib.load('models/xgboost_fraud_detector.pkl')
        
        try:
            with open('models/threshold_config.json', 'r') as f:
                threshold_config = json.load(f)
        except:
            threshold_config = {'threshold_f1': 0.5, 'threshold_recall': 0.3}
        
        tab1, tab2 = st.tabs(["üì§ Upload CSV", "‚ÑπÔ∏è Instru√ß√µes"])
        
        with tab1:
            st.markdown("### üì§ Upload de Arquivo CSV")
            
            st.info("""
            üí° **Formato esperado:**
            - CSV com features V1-V28, Time, Amount
            - Com ou sem coluna 'Class'
            - Feature engineering ser√° aplicado automaticamente
            """)
            
            uploaded_file = st.file_uploader("Fa√ßa upload de um arquivo CSV", type=['csv'])
            
            if uploaded_file is not None:
                df_raw = pd.read_csv(uploaded_file)
                
                st.success(f"‚úÖ Arquivo carregado: {len(df_raw)} transa√ß√µes")
                
                with st.expander("üëÄ Ver dados originais"):
                    st.dataframe(df_raw.head(10), use_container_width=True)
                
                with st.spinner("üîß Aplicando feature engineering..."):
                    df = preprocess_uploaded_data(df_raw)
                
                st.success("‚úÖ Features processadas!")
                
                with st.expander("üîç Ver features ap√≥s processamento"):
                    st.dataframe(df.head(5), use_container_width=True)
                    st.info(f"Total de features: {df.shape[1]}")
                
                threshold = st.slider(
                    "üéØ Ajustar Threshold",
                    min_value=0.0, max_value=1.0,
                    value=threshold_config.get('threshold_f1', 0.5),
                    step=0.05
                )
                
                if st.button("üîç Analisar Transa√ß√µes", type="primary"):
                    with st.spinner("Analisando..."):
                        try:
                            probas = model.predict_proba(df)[:, 1]
                            predictions = (probas >= threshold).astype(int)
                            
                            df_raw['Probabilidade_Fraude'] = probas
                            df_raw['Predi√ß√£o'] = ['üö® FRAUDE' if p == 1 else '‚úÖ Normal' 
                                                   for p in predictions]
                            
                            st.markdown("---")
                            st.subheader("üìä Resumo")
                            
                            n_fraud = predictions.sum()
                            fraud_pct = (n_fraud / len(predictions)) * 100
                            
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("Total", len(df_raw))
                            with col2:
                                st.metric("üö® Fraudes", n_fraud)
                            with col3:
                                st.metric("Taxa", f"{fraud_pct:.2f}%")
                            
                            st.markdown("---")
                            st.dataframe(
                                df_raw.sort_values('Probabilidade_Fraude', ascending=False),
                                use_container_width=True
                            )
                            
                            csv = df_raw.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                "üíæ Download Resultados",
                                csv, "resultados.csv", "text/csv"
                            )
                            
                            fig = px.histogram(
                                df_raw, x='Probabilidade_Fraude', color='Predi√ß√£o',
                                nbins=50, title='Distribui√ß√£o de Probabilidades',
                                color_discrete_map={'‚úÖ Normal': '#2ecc71', 'üö® FRAUDE': '#e74c3c'}
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        
                        except Exception as e:
                            st.error(f"‚ùå Erro: {str(e)}")
        
        with tab2:
            st.markdown("""
            ### ‚ÑπÔ∏è Como Usar
            
            **Formato do CSV:**
            - `V1` at√© `V28`: Features PCA
            - `Amount`: Valor da transa√ß√£o
            - `Time`: Tempo em segundos (opcional)
            
            **Feature Engineering Autom√°tico:**
            - Features temporais
            - Transforma√ß√µes de Amount
            - Features estat√≠sticas
            
            **Download CSV Exemplo:**
            """)
            
            example_data = {'Time': [0, 1, 2], 'V1': [-1.36, 1.19, -0.97],
                          'V2': [0.46, 0.27, -0.62], 'Amount': [149.62, 2.69, 378.66]}
            for i in range(3, 29):
                example_data[f'V{i}'] = [0.0, 0.0, 0.0]
            
            example_df = pd.DataFrame(example_data)
            example_csv = example_df.to_csv(index=False).encode('utf-8')
            
            st.download_button("üì• Baixar Exemplo", example_csv, "exemplo.csv", "text/csv")
    
    except FileNotFoundError:
        st.error("‚ùå Modelo n√£o encontrado! Treine o modelo primeiro.")

# ============================================================
# P√ÅGINA: M√âTRICAS
# ============================================================
elif page == "üìà M√©tricas do Modelo":
    st.header("üìà Performance do Modelo")
    
    try:
        model = joblib.load('models/xgboost_fraud_detector.pkl')
        X_test = pd.read_csv('data/processed/X_test.csv')
        y_test = pd.read_csv('data/processed/y_test.csv').values.ravel()
        
        y_pred = model.predict(X_test)
        y_proba = model.predict_proba(X_test)[:, 1]
        
        from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üéØ Precision", f"{precision_score(y_test, y_pred):.4f}")
        with col2:
            st.metric("üîç Recall", f"{recall_score(y_test, y_pred):.4f}")
        with col3:
            st.metric("‚ö° F1-Score", f"{f1_score(y_test, y_pred):.4f}")
        with col4:
            st.metric("üìà ROC-AUC", f"{roc_auc_score(y_test, y_proba):.4f}")
        
        st.markdown("---")
        
        tab1, tab2 = st.tabs(["üî¢ Confusion Matrix", "üìä Feature Importance"])
        
        with tab1:
            cm = confusion_matrix(y_test, y_pred)
            
            fig = px.imshow(
                cm, text_auto=True,
                labels=dict(x="Predito", y="Real"),
                x=['Normal', 'Fraude'], y=['Normal', 'Fraude'],
                color_continuous_scale='Blues', title='Matriz de Confus√£o'
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with tab2:
            feature_importance = pd.DataFrame({
                'feature': X_test.columns,
                'importance': model.feature_importances_
            }).sort_values('importance', ascending=False).head(20)
            
            fig = px.bar(
                feature_importance, x='importance', y='feature', orientation='h',
                title='Top 20 Features Mais Importantes'
            )
            fig.update_layout(yaxis={'categoryorder': 'total ascending'})
            st.plotly_chart(fig, use_container_width=True)
    
    except Exception as e:
        st.error(f"‚ùå Erro: {str(e)}")

# ============================================================
# P√ÅGINA: SOBRE
# ============================================================
elif page == "‚ÑπÔ∏è Sobre":
    st.header("‚ÑπÔ∏è Sobre o Projeto")
    
    st.markdown("## üéØ Sistema de Detec√ß√£o de Fraude")
    
    st.write("""
    Sistema de Machine Learning para identificar transa√ß√µes fraudulentas 
    em cart√µes de cr√©dito com alta precis√£o.
    """)
    
    st.markdown("---")
    
    # Dataset
    st.subheader("üìä Dataset")
    col1, col2 = st.columns(2)
    
    with col1:
        st.info("""
        **Fonte:** Credit Card Fraud Detection (Kaggle)
        
        **Caracter√≠sticas:**
        - ~284,000 transa√ß√µes
        - Taxa de fraude: 0.17%
        - 28 features PCA + Time + Amount
        """)
    
    with col2:
        st.success("""
        **Link do Dataset:**
        
        [Kaggle - Credit Card Fraud](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
        """)
    
    st.markdown("---")
    
    # Tecnologias
    st.subheader("üîß Tecnologias Utilizadas")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        **Backend:**
        - Python 3.11+
        - Pandas
        - NumPy
        - Scikit-learn
        """)
    
    with col2:
        st.markdown("""
        **Machine Learning:**
        - XGBoost
        - LightGBM
        - Random Forest
        - Imbalanced-learn
        """)
    
    with col3:
        st.markdown("""
        **Visualiza√ß√£o:**
        - Streamlit
        - Plotly
        - Matplotlib
        - Seaborn
        """)
    
    st.markdown("---")
    
    # Metodologia
    st.subheader("üéì Metodologia")
    
    with st.expander("1Ô∏è‚É£ An√°lise Explorat√≥ria", expanded=False):
        st.write("""
        - An√°lise de distribui√ß√µes
        - Identifica√ß√£o de desbalanceamento
        - An√°lise de correla√ß√µes
        - Visualiza√ß√µes interativas
        """)
    
    with st.expander("2Ô∏è‚É£ Feature Engineering", expanded=False):
        st.write("""
        **Features Temporais:**
        - Hour (0-23)
        - Day
        - Time_Period (Manh√£, Tarde, Noite, Madrugada)
        
        **Features de Amount:**
        - Amount_Log (transforma√ß√£o logar√≠tmica)
        - Amount_Sqrt (raiz quadrada)
        - Amount_Bin (categoriza√ß√£o)
        
        **Features Estat√≠sticas:**
        - V_mean, V_std, V_min, V_max
        - V_range, V_median, V_mad
        """)
    
    with st.expander("3Ô∏è‚É£ Modelagem", expanded=False):
        st.write("""
        **Modelos Testados:**
        1. Logistic Regression (baseline)
        2. Random Forest
        3. XGBoost ‚≠ê (melhor resultado)
        4. LightGBM
        
        **T√©cnicas:**
        - Class weights para desbalanceamento
        - SMOTE testado
        - Threshold tuning
        - Valida√ß√£o temporal
        """)
    
    with st.expander("4Ô∏è‚É£ Avalia√ß√£o", expanded=False):
        st.write("""
        **M√©tricas:**
        - Precision: ~94%
        - Recall: ~88%
        - F1-Score: ~91%
        - ROC-AUC: ~0.98
        - PR-AUC: ~0.95 (melhor para dados desbalanceados)
        """)
    
    st.markdown("---")
    
    # Resultados
    st.subheader("üìà Resultados")
    
    results_data = {
        'M√©trica': ['Precision', 'Recall', 'F1-Score', 'ROC-AUC', 'PR-AUC'],
        'Valor': ['94.2%', '87.5%', '90.7%', '0.978', '0.951']
    }
    
    results_df = pd.DataFrame(results_data)
    st.table(results_df)
    
    st.markdown("---")
    
    # Estrutura do Projeto
    st.subheader("üìÅ Estrutura do Projeto")
    
    st.code("""
fraud_detection/
‚îú‚îÄ‚îÄ app.py                    # Dashboard Streamlit
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                 # Dataset original
‚îÇ   ‚îî‚îÄ‚îÄ processed/           # Dados processados
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_engineering.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_modeling.ipynb
‚îú‚îÄ‚îÄ models/                  # Modelos salvos
‚îÇ   ‚îú‚îÄ‚îÄ xgboost_fraud_detector.pkl
‚îÇ   ‚îî‚îÄ‚îÄ threshold_config.json
‚îú‚îÄ‚îÄ src/                     # C√≥digo modularizado
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
    """, language='text')
    
    st.markdown("---")
    
    # Autor
    st.subheader("üë®‚Äçüíª Autor")
    
    col1, col2 = st.columns([1, 3])
    
    with col1:
        st.markdown("**Lucas Stalter**")
    
    with col2:
        st.markdown("""
        - üîó https://github.com/Lucasstalter
        - üíº www.linkedin.com/in/lucas-martins-stalter
        - üìß lucasstalter@gmail.com
        """)
    
    st.markdown("---")
    
    # Como Usar
    st.subheader("üöÄ Como Usar Este Projeto")
    
    tab1, tab2, tab3 = st.tabs(["üíª Local", "üåê Deploy", "üìö Recursos"])
    
    with tab1:
        st.code("""
# 1. Clonar reposit√≥rio
git clone https://github.com/Lucasstalter/Detec--o_de_Fraude.git
cd Detec--o_de_Fraude

# 2. Criar ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\\Scripts\\activate  # Windows

# 3. Instalar depend√™ncias
pip install -r requirements.txt

# 4. Baixar dataset
# Kaggle: creditcardfraud
# Colocar em: data/raw/creditcard.csv

# 5. Executar notebooks (ordem)
jupyter notebook
# 01_eda.ipynb
# 02_feature_engineering.ipynb
# 03_modeling.ipynb

# 6. Rodar dashboard
streamlit run app.py
        """, language='bash')
    
    with tab2:
        st.markdown("""
        ### Deploy no Streamlit Cloud (Gratuito)
        
        1. Acesse: https://streamlit.io/cloud
        2. Login com GitHub
        3. New app
        4. Selecione o reposit√≥rio
        5. Main file: `app.py`
        6. Deploy! üöÄ
        
        Seu app ficar√° online em minutos!
        """)
    
    with tab3:
        st.markdown("""
        ### üìö Recursos √öteis
        
        **Documenta√ß√£o:**
        - [Streamlit Docs](https://docs.streamlit.io)
        - [XGBoost Docs](https://xgboost.readthedocs.io)
        - [Scikit-learn](https://scikit-learn.org)
        
        **Artigos:**
        - [Handling Imbalanced Data](https://imbalanced-learn.org)
        - [Feature Engineering Guide](https://scikit-learn.org/stable/modules/preprocessing.html)
        
        **Dataset Original:**
        - [Kaggle - Credit Card Fraud](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
        """)
    
    st.markdown("---")
    
    # Licen√ßa
    st.subheader("üìù Licen√ßa")
    st.info("MIT License - Uso livre para fins educacionais e comerciais")
    
    st.markdown("---")
    
    # Footer especial
    st.success("üí° **Projeto desenvolvido como portfolio de Machine Learning**")
    
# Footer
st.markdown("---")
st.markdown(
    "<div style='text-align: center'> @ 2026 Lucas Stalter</div>",
    unsafe_allow_html=True
)