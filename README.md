# ğŸ” Sistema de DetecÃ§Ã£o de Fraude com Machine Learning

<div align="center">

![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Status-Completo-success.svg)
![ML](https://img.shields.io/badge/ML-XGBoost-orange.svg)
![Streamlit](https://img.shields.io/badge/Dashboard-Streamlit-red.svg)

Sistema de Machine Learning para detecÃ§Ã£o de transaÃ§Ãµes fraudulentas em cartÃµes de crÃ©dito com **94%+ de precisÃ£o**.


</div>

---

## ğŸ“‹ Ãndice

- [Sobre o Projeto](#-sobre-o-projeto)
- [Resultados](#-resultados)
- [Tecnologias](#-tecnologias)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Como Usar](#-como-usar)
- [Metodologia](#-metodologia)
- [Autor](#-autor)

---

## ğŸ¯ Sobre o Projeto

Sistema completo de detecÃ§Ã£o de fraude utilizando tÃ©cnicas avanÃ§adas de Machine Learning para identificar transaÃ§Ãµes fraudulentas em tempo real.

### ğŸŒŸ Destaques

- âœ… **Alta PrecisÃ£o**: 94.2% de precision, 87.5% de recall
- âœ… **Feature Engineering AvanÃ§ado**: 40+ features criadas
- âœ… **Dashboard Interativo**: Interface web com Streamlit
- âœ… **MÃºltiplos Modelos**: XGBoost, LightGBM, Random Forest
- âœ… **Tratamento de Desbalanceamento**: SMOTE, class weights
- âœ… **ProduÃ§Ã£o Ready**: Modelo salvo e pronto para deploy

### ğŸ“Š Dataset

- **Fonte**: [Credit Card Fraud Detection - Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- **Tamanho**: 284,807 transaÃ§Ãµes
- **Features**: 28 features (resultado de PCA) + Time + Amount
- **Taxa de Fraude**: 0.172% (dados altamente desbalanceados)

---

## ğŸ“ˆ Resultados

### MÃ©tricas do Modelo Final (XGBoost)

| MÃ©trica | Valor | DescriÃ§Ã£o |
|---------|-------|-----------|
| **Precision** | 94.2% | Dos alertas de fraude, 94% sÃ£o corretos |
| **Recall** | 87.5% | Das fraudes reais, 87% sÃ£o detectadas |
| **F1-Score** | 90.7% | MÃ©dia harmÃ´nica entre Precision e Recall |
| **ROC-AUC** | 0.978 | Excelente capacidade de discriminaÃ§Ã£o |
| **PR-AUC** | 0.951 | Ideal para dados desbalanceados |

### ğŸ“Š ComparaÃ§Ã£o de Modelos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Modelo              â”‚ Precision â”‚ Recall â”‚ F1-Score â”‚ ROC-AUC â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Logistic Regression â”‚   89.3%   â”‚ 78.2%  â”‚  83.4%   â”‚  0.912  â”‚
â”‚ Random Forest       â”‚   91.7%   â”‚ 84.1%  â”‚  87.7%   â”‚  0.965  â”‚
â”‚ XGBoost â­          â”‚   94.2%   â”‚ 87.5%  â”‚  90.7%   â”‚  0.978  â”‚
â”‚ LightGBM            â”‚   93.1%   â”‚ 86.3%  â”‚  89.6%   â”‚  0.971  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tecnologias

### Core

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)

### Machine Learning

- **XGBoost** - Modelo principal
- **LightGBM** - Alternativa rÃ¡pida
- **Random Forest** - Ensemble
- **Imbalanced-learn** - SMOTE e tÃ©cnicas de balanceamento

### VisualizaÃ§Ã£o

- **Streamlit** - Dashboard interativo
- **Plotly** - GrÃ¡ficos interativos
- **Matplotlib** - VisualizaÃ§Ãµes estÃ¡ticas
- **Seaborn** - GrÃ¡ficos estatÃ­sticos

### DevOps

![Git](https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white)
![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)
![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white)

---

## ğŸ“ Estrutura do Projeto

```
fraud_detection/
â”‚
â”œâ”€â”€ ğŸ“Š app.py                          # Dashboard Streamlit
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ raw/                           # Dados originais (nÃ£o versionados)
â”‚   â”‚   â””â”€â”€ creditcard.csv
â”‚   â””â”€â”€ processed/                     # Dados processados
â”‚       â”œâ”€â”€ X_train.csv
â”‚       â”œâ”€â”€ X_test.csv
â”‚       â”œâ”€â”€ y_train.csv
â”‚       â””â”€â”€ y_test.csv
â”‚
â”œâ”€â”€ ğŸ““ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb                   # AnÃ¡lise ExploratÃ³ria
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb   # Engenharia de Features
â”‚   â””â”€â”€ 03_modeling.ipynb              # Modelagem e AvaliaÃ§Ã£o
â”‚
â”œâ”€â”€ ğŸ¤– models/
â”‚   â”œâ”€â”€ xgboost_fraud_detector.pkl     # Modelo treinado
â”‚   â”œâ”€â”€ scaler.pkl                     # Scaler para normalizaÃ§Ã£o
â”‚   â””â”€â”€ threshold_config.json          # ConfiguraÃ§Ãµes de threshold
â”‚
â”œâ”€â”€ ğŸ’» src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ data_loader.py             # Carregamento de dados
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ feature_engineering.py     # CriaÃ§Ã£o de features
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ train.py                   # Treinamento
â”‚   â””â”€â”€ visualization/
â”‚       â””â”€â”€ plots.py                   # VisualizaÃ§Ãµes
â”‚
â”œâ”€â”€ ğŸ“‹ requirements.txt                 # DependÃªncias
â”œâ”€â”€ ğŸ“– README.md                        # Este arquivo
â””â”€â”€ ğŸš« .gitignore                       # Arquivos ignorados
```

---

## ğŸš€ Como Usar

### 1ï¸âƒ£ PrÃ©-requisitos

- Python 3.11+
- pip
- Git

### 2ï¸âƒ£ InstalaÃ§Ã£o

```bash
# Clonar repositÃ³rio
git clone https://github.com/Lucasstalter/Detec--o_de_Fraude.git
cd Detec--o_de_Fraude

# Criar ambiente virtual
python -m venv venv

# Ativar ambiente virtual
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 3ï¸âƒ£ Obter Dataset

1. Baixe o dataset: [Kaggle - Credit Card Fraud](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
2. Extraia o arquivo `creditcard.csv`
3. Coloque em: `data/raw/creditcard.csv`

### 4ï¸âƒ£ Executar Notebooks (Ordem)

```bash
# Iniciar Jupyter
jupyter notebook

# Executar notebooks na ordem:
# 1. notebooks/01_eda.ipynb
# 2. notebooks/02_feature_engineering.ipynb
# 3. notebooks/03_modeling.ipynb
```

### 5ï¸âƒ£ Rodar Dashboard

```bash
streamlit run app.py
```

O dashboard abrirÃ¡ automaticamente em: `http://localhost:8501`

---

## ğŸ”¬ Metodologia

### 1. AnÃ¡lise ExploratÃ³ria (EDA)

- âœ… AnÃ¡lise de distribuiÃ§Ãµes
- âœ… IdentificaÃ§Ã£o de outliers
- âœ… AnÃ¡lise de correlaÃ§Ãµes
- âœ… VisualizaÃ§Ã£o de padrÃµes temporais
- âœ… Estudo do desbalanceamento (0.172% fraudes)

### 2. Feature Engineering

#### Features Temporais
```python
Hour = (Time / 3600) % 24              # Hora do dia
Day = (Time / 86400)                   # Dia desde inÃ­cio
Time_Period = categorize_by_period()   # ManhÃ£, Tarde, Noite
```

#### Features de Amount
```python
Amount_Log = log1p(Amount)             # TransformaÃ§Ã£o log
Amount_Sqrt = sqrt(Amount)             # Raiz quadrada
Amount_Bin = categorize(Amount)        # CategorizaÃ§Ã£o
```

#### Features EstatÃ­sticas
```python
V_mean = mean(V1...V28)                # MÃ©dia das V features
V_std = std(V1...V28)                  # Desvio padrÃ£o
V_range = max(V1...V28) - min(V1...V28)  # Range
V_mad = mean_absolute_deviation()      # MAD
```

**Total**: 47 features (28 originais + 19 engineered)

### 3. Tratamento de Desbalanceamento

- âš–ï¸ **Class Weights**: Penalizar mais fraudes nÃ£o detectadas
- ğŸ”„ **SMOTE**: Synthetic Minority Over-sampling (testado)
- ğŸ¯ **Threshold Tuning**: Ajuste fino do limiar de decisÃ£o
- â±ï¸ **ValidaÃ§Ã£o Temporal**: Split temporal (nÃ£o aleatÃ³rio)

### 4. Modelagem

#### Modelos Testados
1. **Logistic Regression** - Baseline
2. **Random Forest** - Ensemble
3. **XGBoost** â­ - Melhor resultado
4. **LightGBM** - Alternativa rÃ¡pida

#### HiperparÃ¢metros (XGBoost)
```python
{
    'n_estimators': 100,
    'max_depth': 6,
    'learning_rate': 0.1,
    'scale_pos_weight': 577,  # Balancear classes
    'eval_metric': 'logloss'
}
```

### 5. AvaliaÃ§Ã£o

**MÃ©tricas Principais:**
- âœ… **Precision**: Evitar falsos positivos
- âœ… **Recall**: Capturar mÃ¡ximo de fraudes
- âœ… **F1-Score**: BalanÃ§o entre Precision e Recall
- âœ… **PR-AUC**: Melhor para dados desbalanceados

---

## ğŸ¨ Dashboard Interativo

### Funcionalidades

#### ğŸ  **Home**
- VisÃ£o geral do sistema
- MÃ©tricas principais em cards
- EstatÃ­sticas atualizadas

#### ğŸ“Š **AnÃ¡lise de Dados**
- ExploraÃ§Ã£o interativa do dataset
- DistribuiÃ§Ãµes por feature
- Matriz de correlaÃ§Ã£o
- Box plots comparativos

#### ğŸ¤– **PrediÃ§Ã£o** â­
- Upload de CSV
- Feature engineering automÃ¡tico
- Ajuste de threshold em tempo real
- Download de resultados
- VisualizaÃ§Ãµes das prediÃ§Ãµes

#### ğŸ“ˆ **MÃ©tricas do Modelo**
- Confusion Matrix interativa
- Top 20 features mais importantes
- AnÃ¡lise de threshold
- Curvas ROC e Precision-Recall

#### â„¹ï¸ **Sobre**
- DocumentaÃ§Ã£o completa
- Metodologia detalhada
- Como usar
- InformaÃ§Ãµes do autor

---



## ğŸ‘¨â€ğŸ’» Autor

<div align="center">

### Lucas Stalter


**Data Scientist | Machine Learning Engineer**

</div>




---

<div align="center">

**Desenvolvido por Lucas Stalter**


</div>
